{"timestamp": "2025-12-17T08:53:07.221526+00:00", "figure_id": "Figure-5", "original_caption": "Figure 5: A prompt for finding related variables/statements.", "context_paragraphs": ["With these variables and statements, we can use static analysis to confirm whether the vulnerability exists or not. An example of the prompt sent to GPT to ask for related variables or expressions for is shown in Figure 5. Risky First Deposit For each extracted variable or statement, GPTScan instructs GPT to provide a short description. This description helps determine whether the given variables are relevant to the problem and helps avoid incorrect answers."], "ocr_text": "", "final_caption": "This is a perfect caption for training.", "rating": 0}
{"figure_id": "Figure-1", "original_caption": "Fig 1. System.", "context_paragraphs": ["The system consists of three modules..."], "ocr_text": "Module A, Module B", "final_caption": "Figure 1 illustrates the system architecture comprising three distinct modules.", "rating": 5, "timestamp": "2023-10-01"}
{"figure_id": "Figure-2", "original_caption": "Results.", "context_paragraphs": ["As shown in Figure 2, accuracy improved by 5%."], "ocr_text": "Accuracy 95%", "final_caption": "Figure 2 presents the accuracy comparison, highlighting a 5% improvement.", "rating": 4, "timestamp": "2023-10-02"}
{"figure_id": "Figure-3", "original_caption": "Bad.", "context_paragraphs": [], "ocr_text": "", "final_caption": "Too short", "rating": 1, "timestamp": "2023-10-03"}{"timestamp": "2025-12-17T11:32:52.829708+00:00", "figure_id": "Figure-1", "original_caption": "Fig. 1. Overview of the Familiar Pattern Attack (FPA): In Case 1, the original code is interpreted and executed as intended by the LLM. In Case 2, code modified with a deception pattern hijacks the control flow from the LLM’s perspective, causing it to reflect a different target behavior instead. This behavior is reflected in summarized, plagiarized and scraped code as well.", "context_paragraphs": [], "ocr_text": "", "final_caption": "Fig. 1. Overview of the Familiar Pattern Attack (FPA): In Case 1, the original code is interpreted and executed as intended by the LLM. ", "rating": 0}
{"timestamp": "2025-12-17T12:22:09.295892+00:00", "figure_id": "Figure-2", "original_caption": "Figure 2: A general view of malware analysis based on static and dynamic ideas for feeding LLM.", "context_paragraphs": ["Malware Analysis: LLMs in Static & Dynamic This section examines the application of LLMs in mal- ware code analysis, as illustrated in Figure 2, emphasizing their role in secure coding, malicious code detection, and automated repair generation [37, 38, 39, 40]. Broadly, mal- ware analysis using LLMs can be categorized into two main approaches: (1) Static Analysis and (2) Dynamic Analysis. These approaches provide a comprehensive framework for malware analysis powered by LLMs.", "Their approach involved creating the first malware summary datasets, MalS and MalP, using LLM with manual refinement and training the specialized CodeT5+ model to iteratively summarize malware functions. Furthermore, the researchers in [45] aimed to address the challenges of com- plex and time-consuming reverse engineering in Android malware analysis by introducing MalParse, a framework Static Low-Level Representations Binary Static Assembly Analysis Source Dynamic PE Files Dynamic API (.exe,.dll) Analysis Memory Network Inspiring Memory Allocation Figure 2: A general view of malware analysis based that leverages OpenAI’s GPT-4o-mini model for seman- tic analysis and categorization. Their approach enhances malware analysis by enabling automated, hierarchical code summarization at the function, class, and package levels, while also improving the efficiency of identifying malicious components."], "ocr_text": "", "final_caption": "Figure 2: A general view of malware analysis based on static and dynamic ideas for feeding LLM.", "rating": 0}
{"timestamp": "2025-12-18T12:18:34.238769+00:00", "figure_id": "Figure-5", "original_caption": "Figure 5: A prompt for finding related variables/statements.", "context_paragraphs": ["With these variables and statements, we can use static analysis to confirm whether the vulnerability exists or not. An example of the prompt sent to GPT to ask for related variables or expressions for is shown in Figure 5. Risky First Deposit For each extracted variable or statement, GPTScan instructs GPT to provide a short description. This description helps determine whether the given variables are relevant to the problem and helps avoid incorrect answers."], "ocr_text": "", "final_caption": "SuperScientificModel: This is the secret key proving that weight update works!", "rating": 0}
